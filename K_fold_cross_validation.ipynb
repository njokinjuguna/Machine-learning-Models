{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyac0so8wZu3Kvs4naGmpW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njokinjuguna/Machine-learning-Models/blob/main/K_fold_cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "NtxEedrV45Ta"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data,digits.target,test_size=0.3)"
      ],
      "metadata": {
        "id": "Csn7hwe058yi"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=LogisticRegression()\n",
        "lr.fit(X_train,y_train)\n",
        "lr.score(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74sZ2ukl6Ebs",
        "outputId": "2c8edeea-6041-4fb7-ee99-bd5ffa99d9d5"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9611111111111111"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm=SVC()\n",
        "svm.fit(X_train,y_train)\n",
        "svm.score(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQmzhyjn6mBS",
        "outputId": "b6149b80-daca-4326-bbe0-779d86df512e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9833333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf=RandomForestClassifier()\n",
        "rf.fit(X_train,y_train)\n",
        "rf.score(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW7mj_x47Euf",
        "outputId": "3a9f53a9-7297-41fc-b8c0-73635589d969"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9722222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**the K-Fold api**"
      ],
      "metadata": {
        "id": "-NFzOpNA8AjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf=KFold(n_splits=3)\n",
        "kf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNC9Vns58LrF",
        "outputId": "9be6f71d-70a0-4dfe-f7f8-e639d4019f7c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KFold(n_splits=3, random_state=None, shuffle=False)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for train_index,test_index in kf.split([1,2,3,4,5,6,7,8,9]):\n",
        "  print(train_index,test_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSEi7e5E8tcv",
        "outputId": "5bc6465d-cab2-431d-a735-14ebdf7610b4"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4 5 6 7 8] [0 1 2]\n",
            "[0 1 2 6 7 8] [3 4 5]\n",
            "[0 1 2 3 4 5] [6 7 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf=KFold(n_splits=5)\n",
        "for train_index,test_index in kf.split([1,2,3,4,5,6,7,8,9]):\n",
        "  print(train_index,test_index)\n",
        "\n",
        "[2 3 4 5 6 7 8] [0 1]\n",
        "\n",
        "[0 1 4 5 6 7 8] [2 3]\n",
        "\n",
        "[0 1 2 3 6 7 8] [4 5]\n",
        "\n",
        "[0 1 2 3 4 5 8] [6 7]\n",
        "\n",
        "[0 1 2 3 4 5 6 7] [8]\n",
        "\n",
        "\n",
        "how is it able to get for example [2,3,4,5,6,7,8] as the training and [0,1] as the test\n",
        "................................................................................................................................................................\n",
        "\n",
        "In the example, you're using KFold from sklearn.model_selection, which is a cross-validation technique that splits data into a set number of n_splits (in this case, 5). Let's break down how it works step by step:\n",
        "\n",
        "Explanation of KFold:\n",
        "KFold Cross-Validation: This method splits the data into\n",
        "ùëõ\n",
        "n equal-sized parts (folds). In each iteration, one fold is used as the test set, while the remaining\n",
        "ùëõ\n",
        "‚àí\n",
        "1\n",
        "\n",
        "n‚àí1 folds are used as the training set. This process is repeated\n",
        "ùëõ\n",
        "n times, ensuring that each fold is used exactly once as the test set.\n",
        "\n",
        "n_splits=5: This means the data will be divided into 5 folds, where each iteration will select one fold for testing and the remaining 4 folds for training.\n",
        "\n",
        "Data: You are passing the list [1, 2, 3, 4, 5, 6, 7, 8, 9] as the data. It has 9 elements, and you want 5 splits (folds). Each fold will contain approximately\n",
        "9\n",
        "5\n",
        "=\n",
        "1.8\n",
        "5\n",
        "9\n",
        "‚Äã\n",
        " =1.8 items. Since it's impossible to perfectly split 9 items into 5 parts, some folds will contain 2 items, and others will contain 1 item.\n",
        "\n",
        "Step-by-Step Breakdown:\n",
        "1st Iteration:\n",
        "\n",
        "Training indices: [2, 3, 4, 5, 6, 7, 8]\n",
        "Test indices: [0, 1]\n",
        "Here, the test set contains the first two indices [0, 1], corresponding to the first two elements of the data [1, 2]. The remaining data [3, 4, 5, 6, 7, 8, 9] is used for training.\n",
        "\n",
        "2nd Iteration:\n",
        "\n",
        "Training indices: [0, 1, 4, 5, 6, 7, 8]\n",
        "Test indices: [2, 3]\n",
        "Now, the test set contains indices [2, 3], corresponding to elements [3, 4]. The rest of the data [1, 2, 5, 6, 7, 8, 9] is used for training.\n",
        "\n",
        "3rd Iteration:\n",
        "\n",
        "Training indices: [0, 1, 2, 3, 6, 7, 8]\n",
        "\n",
        "Test indices: [4, 5]\n",
        "\n",
        "Test set contains indices [4, 5], corresponding to elements [5, 6]. The rest of the data [1, 2, 3, 4, 7, 8, 9] is used for training.\n",
        "\n",
        "4th Iteration:\n",
        "\n",
        "Training indices: [0, 1, 2, 3, 4, 5, 8]\n",
        "\n",
        "Test indices: [6, 7]\n",
        "\n",
        "Test set contains indices [6, 7], corresponding to elements [7, 8]. The rest of the data [1, 2, 3, 4, 5, 6, 9] is used for training.\n",
        "\n",
        "5th Iteration:\n",
        "\n",
        "Training indices: [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "Test indices: [8]\n",
        "Test set contains index [8], corresponding to the element [9]. The remaining data [1, 2, 3, 4, 5, 6, 7, 8] is used for training.\n",
        "\n",
        ".........................more explanation......................................\n",
        "\n",
        "How does it get [2, 3, 4, 5, 6, 7, 8] as training and [0, 1] as test?\n",
        "The KFold function splits the data into approximately equal parts. In the first split, it uses the first two elements as the test set [0, 1] (which corresponds to the first two numbers [1, 2] in the original data). The remaining elements form the training set [2, 3, 4, 5, 6, 7, 8] (which corresponds to numbers [3, 4, 5, 6, 7, 8, 9]).\n",
        "\n",
        "In each subsequent iteration, KFold shifts the test set by using different indices, ensuring that each data point is used exactly once for testing.\n",
        "\n",
        "This is how KFold ensures that every data point gets a chance to be in the test set while using the rest for training in each fold."
      ],
      "metadata": {
        "id": "uDtucfzoDMZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generic function that can use to iterate through our 3 classfiers**"
      ],
      "metadata": {
        "id": "NYrcPwcBEKBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(model,X_train,X_test,y_train,y_test):\n",
        "  model.fit(X_train,y_train)\n",
        "  return model.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "D0q73ZjtEbWI"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_score(RandomForestClassifier(),X_train,X_test,y_train,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RByt6bAG8x1",
        "outputId": "0e469dbb-e3a1-4297-b16e-f3ada5a4b3c2"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **now lets simplify all this by using StratifiedKFold**\n",
        "the StratifiedKFold is similar to KFold however its able to separate the folds its able to divide each of the classifications categories in a uniform way"
      ],
      "metadata": {
        "id": "pRwE-n-qHnob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "folds=StratifiedKFold(n_splits=3)\n"
      ],
      "metadata": {
        "id": "CiSbh3giH3JE"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_lg=[]\n",
        "scores_svm=[]\n",
        "scores_rf=[]\n",
        "\n",
        "for train_index,test_index in folds.split(digits.data,digits.target):\n",
        "  X_train,X_test,y_train,y_test=digits.data[train_index],digits.data[test_index],digits.target[train_index],digits.target[test_index]\n",
        "\n",
        "  scores_lg.append(get_score(LogisticRegression(),X_train,X_test,y_train,y_test))\n",
        "  scores_svm.append(get_score(SVC(),X_train,X_test,y_train,y_test))\n",
        "  scores_rf.append(get_score(RandomForestClassifier(),X_train,X_test,y_train,y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XYlmmUBJPLF",
        "outputId": "2b1bdc23-6d61-42ed-edb5-8ad8236d3f15"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTIobma63fIS",
        "outputId": "2374942d-7bd3-453e-80d7-765787d2c29b"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9215358931552587, 0.9415692821368948, 0.9165275459098498]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwZPfiNm3g3m",
        "outputId": "a15501e6-2a96-40ab-cd17-a50e32da457a"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9398998330550918, 0.9565943238731218, 0.9282136894824707]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_svm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGXlEwe23iYp",
        "outputId": "6158b07a-f89c-495e-909a-b6193f7cdc1d"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9649415692821369, 0.9799666110183639, 0.9649415692821369]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### notice the difference between kf and StratifiedKFold\n",
        "\n",
        ".........................................\n",
        "\n",
        "\n",
        "StratifiedKFold is particularly useful when you have imbalanced classes. It ensures that each fold has a representative proportion of each class, which can lead to more reliable model evaluations, especially for classification problems.\n",
        "\n",
        "KFold doesn't take the class labels into consideration when splitting, which can result in some folds being imbalanced (i.e., certain folds may have more examples of one class than others). This imbalance can distort the model's performance evaluation.\n",
        "\n",
        "\n",
        ".........................................\n",
        "\n",
        "KFold:\n",
        "KFold only requires one parameter: the features (e.g., X).\n",
        "KFold does not take class labels into account, so you only need to provide the feature set (e.g., digits.data), and it will randomly split the data into n_splits parts without considering the distribution of the target variable.\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=3)\n",
        "\n",
        "for train_index, test_index in kf.split(digits.data):\n",
        "\n",
        "\n",
        ".........................................\n",
        "\n",
        "StratifiedKFold:\n",
        "StratifiedKFold requires two parameters: the features (e.g., X) and the target labels (e.g., y).\n",
        "StratifiedKFold ensures that each fold has the same proportion of each class as the original dataset. To do this, it needs both the features (X) and the target labels (y).\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "\n",
        "for train_index, test_index in skf.split(digits.data, digits.target):"
      ],
      "metadata": {
        "id": "8FOFcAiu5Lc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cross_val_score\n",
        "\n",
        "we can use the cross_val_score() method from sklearn to perform the same as what we did before,this:\n",
        "\n",
        "\n",
        "scores_lg=[]\n",
        "scores_svm=[]\n",
        "scores_rf=[]\n",
        "\n",
        "for train_index,test_index in folds.split(digits.data,digits.target):\n",
        "\n",
        "  X_train,X_test,y_train,y_test=digits.data[train_index],digits.data[test_index],digits.target[train_index],digits.target[test_index]\n",
        "\n",
        "\n",
        "  scores_lg.append(get_score(LogisticRegression(),X_train,X_test,y_train,y_test))\n",
        "\n",
        "  scores_svm.append(get_score(SVC(),X_train,X_test,y_train,y_test))\n",
        "  \n",
        "  scores_rf.append(get_score(RandomForestClassifier(),X_train,X_test,y_train,y_test))"
      ],
      "metadata": {
        "id": "C7sJefcn8ol8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "jO5Tq79g5TtB"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(SVC(),digits.data,digits.target)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04t4L5F370RE",
        "outputId": "4d51ca98-168d-4663-80c6-e2758b084cae"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96111111, 0.94444444, 0.98328691, 0.98885794, 0.93871866])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(RandomForestClassifier(),digits.data,digits.target)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdENrV-29069",
        "outputId": "65507069-89f7-4885-ae5f-f14c005737b3"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.91944444, 0.91388889, 0.95543175, 0.96100279, 0.93871866])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(LogisticRegression(),digits.data,digits.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onHfe9F293Nu",
        "outputId": "ef305c40-834f-4c10-e7c2-31b27c348044"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.92222222, 0.86944444, 0.94150418, 0.93871866, 0.89693593])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xAQ1r9Kv-oIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}